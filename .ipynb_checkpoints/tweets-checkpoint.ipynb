{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in datasets and parse dates\n",
    "obama = pd.read_csv(\"./data/obama.csv\",\n",
    "                    parse_dates=[\"Date\"])\n",
    "trump = pd.read_csv(\"./data/trump.csv\",\n",
    "                    parse_dates=[\"created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop NAs\n",
    "obama = obama.dropna(axis=0, how =\"any\")\n",
    "trump = trump.dropna(axis=0, how =\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create corpus of Obama tweets\n",
    "obama_tweets = []\n",
    "for i in range(len(obama)):\n",
    "    obama_tweets.append(obama.iloc[i,0])\n",
    "    \n",
    "# Create corpus of Trump tweets\n",
    "trump_tweets = []\n",
    "for i in range(len(trump)):\n",
    "    trump_tweets.append(trump.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate count vectorizers\n",
    "# Make all words lowercase, remove English stopwords, and create 1- and 2-word n-grams\n",
    "cv_obama = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1,2))\n",
    "cv_trump = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama:  (6734, 48770)\n",
      "Trump:  (34579, 256869)\n"
     ]
    }
   ],
   "source": [
    "# Create term-document matrices: rows represent tweets, columns represent words in the vocabulary\n",
    "tfidf_obama = cv_obama.fit_transform(obama_tweets)\n",
    "tfidf_trump = cv_trump.fit_transform(trump_tweets)\n",
    "\n",
    "print(\"Obama: \", tfidf_obama.shape)\n",
    "print(\"Trump: \", tfidf_trump.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model with 20 topics\n",
    "lda_obama = LatentDirichletAllocation(n_components=20)\n",
    "lda_trump = LatentDirichletAllocation(n_components=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=DeprecationWarning) # to remove warnings\n",
    "# Run LDA on the term-frequency vectorizer objects (note: this takes around ten minutes, depending on the machine)\n",
    "X_lda_obama = lda_obama.fit_transform(tfidf_obama)\n",
    "X_lda_trump = lda_trump.fit_transform(tfidf_trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# An auxiliary function to print out the most likely terms for each topic\n",
    "# Taken from https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic {:#2d}: \".format(topic_idx+1)\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in Barack Obama LDA model:\n",
      "\n",
      "Topic  1: ofa bo ofa bo http ofa http change climate actonclimate climate change read\n",
      "Topic  2: president ve america world fact got pass year ve got budget\n",
      "Topic  3: jobs job 000 economy education growth months private added sector\n",
      "Topic  4: obama president obama president live live president speaking obama speaking sotu opportunityforall just\n",
      "Topic  5: insurance health health insurance million americans country 1st obamacare enroll 1st http\n",
      "Topic  6: cuts immigrants madeinamerica dream living balanced manufacturing debate budget cuts standwithourfuture\n",
      "Topic  7: tell congress renewui helped comes political peace momentum thisiswhypic twitter thisiswhypic giving\n",
      "Topic  8: wage minimum minimum wage families raisethewage hard working taking forward raising\n",
      "Topic  9: watch et tune watch president http speak et watch watch live tune http 11\n",
      "Topic 10: immigrationreform word spread spread word 200 john improving face challenges supports\n",
      "Topic 11: president obama president obama address watch weekly weekly address http ofa bo bo\n",
      "Topic 12: act care affordable care affordable care act background checks background checks movement checks gun\n",
      "Topic 13: ofa bo ofa bo http ofa http twitter com twitter com pic pic twitter\n",
      "Topic 14: real want best making check options hear background check background plans\n",
      "Topic 15: people care health care health economic american affordable college american people ofa volunteers\n",
      "Topic 16: future taxes place tax www close fact issue leadontrade thisiswhy\n",
      "Topic 17: rt energy rt agree clean actonreform create cost clean energy plan pre\n",
      "Topic 18: make health women care make sure sure young health care right power\n",
      "Topic 19: nation deserve doesn doing women day leave mean families americans http\n",
      "Topic 20: stay speakerboehner 2012 organizing christmas congressional require involved enda finish\n",
      "\n",
      "Topics in Donald Trump LDA model:\n",
      "\n",
      "Topic  1: celebapprentice pay totally spending tv report donaldtrump comes midas midas touch\n",
      "Topic  2: love really great success time amp season doing miss discussing\n",
      "Topic  3: hillary 2016 nice election record clinton crooked campaign things said\n",
      "Topic  4: like obama mr did amp mr trump don won people just\n",
      "Topic  5: realdonaldtrump barackobama interview trump2016 happy https doesn ratings watching sad\n",
      "Topic  6: best amp tax history real nyc global winner cut military\n",
      "Topic  7: https cont http makeamericagreatagain today join chicago world god welcome makeamericagreatagain https\n",
      "Topic  8: obama debt use problem just fired play money talking point\n",
      "Topic  9: realdonaldtrump great thank america make https true tonight night trump\n",
      "Topic 10: trump donald realdonaldtrump donald trump president good believe https luck read\n",
      "Topic 11: apprentice mittromney hope ll book celebrity com celebrity apprentice scotland jeb\n",
      "Topic 12: run china business looking course golf just president run president poll\n",
      "Topic 13: http trump obamacare president disaster iraq realdonaldtrump president trump http law interview discussing\n",
      "Topic 14: jobs job great beautiful amp great job fast thank https congress\n",
      "Topic 15: thanks think president obama say trump got agree wow big\n",
      "Topic 16: yesterday tower pm trump tower awesome club trump national video ties 2012\n",
      "Topic 17: better deal million usa art stop art deal coming mexico build\n",
      "Topic 18: great new work hard vote want win guy state amp\n",
      "Topic 19: right cont trump amp hotel wait office florida life wind\n",
      "Topic 20: american need country needs republicans americans people https president great\n"
     ]
    }
   ],
   "source": [
    "obama_features = cv_obama.get_feature_names()\n",
    "trump_features = cv_trump.get_feature_names()\n",
    "print(\"\\nTopics in Barack Obama LDA model:\\n\")\n",
    "print_top_words(lda_obama, obama_features, 10)\n",
    "print(\"\\nTopics in Donald Trump LDA model:\\n\")\n",
    "print_top_words(lda_trump, trump_features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
